**RAG (Retrieval-Augmented Generation)** — это передовая архитектура в искусственном интеллекте, которая сочетает в себе **поиск** информации из внешних источников (баз знаний) и **генерацию** ответов.

Проще говоря, это технология, которая позволяет таким моделям, как ChatGPT, **"заглядывать в свои notes" (базу знаний)** перед тем, как ответить на вопрос. Это делает ответы более точными, актуальными и лишёнми "галлюцинаций".

Процесс RAG можно представить в виде трёх этапов:

**1. Retrieval (Поиск)**

- Когда пользователь задаёт вопрос (запрос), система не отправляет его сразу в LLM.
    
- Вместо этого она сначала ищет **наиболее релевантные документы** из заранее подготовленной базы знаний. Эта база может содержать PDF-файлы, статьи, документацию, данные с сайтов и т.д.
    
- Поиск происходит с помощью **векторного поиска**. И запрос пользователя, и все документы в базе преобразуются в **эмбеддинги** (числовые векторы). Система находит документы, векторы которых ближе всего к вектору запроса.
    

**2. Augmentation (Обогащение)**

- Найденные релевантные фрагменты текста (например, 2-3 самых подходящих абзаца) **добавляются к оригинальному запросу пользователя**.
    
- Формируется новый, расширенный (обогащённый) prompt (запрос к модели), который выглядит примерно так:
    
    > "Используй строго следующую информацию из нашей базы знаний:  
    > [Здесь вставляется найденный релевантный текст]
    > 
    > Ответь на вопрос пользователя на основе ЭТОЙ информации:  
    > Вопрос: [Оригинальный вопрос пользователя]"
    

**3. Generation (Генерация)**

- Этот обогащённый prompt отправляется в большую языковую модель (например, GPT-4).
    
- Модель не полагается на свою память, а **генерирует ответ, основываясь исключительно на предоставленных ей документах**.
    
- В результате пользователь получает точный, обоснованный ответ с ссылкой на источник (если система это предусматривает).